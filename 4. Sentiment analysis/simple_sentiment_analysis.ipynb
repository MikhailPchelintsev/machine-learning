{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализа тональности отзывов на примере сентимент-анализа отзывов на фильмы из стандартного датасета nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id негативных и позитивных отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список негативных отзывов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negreviews = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posreviews  = [movie_reviews.words(fileids=[f]) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Негативных отзывов 1000 штук\n"
     ]
    }
   ],
   "source": [
    "print 'Негативных отзывов {} штук'.format(len(negreviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позитивных отзывов отзывов 1000 штук\n"
     ]
    }
   ],
   "source": [
    "print 'Позитивных отзывов отзывов {} штук'.format(len(posreviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negreviews - list содержащий отзывы, каждый отзыв - list элементами которого являются отдельные слова отзыва.\n",
    "CountVectorizer на вход принимет  лист содержащий отзывы в виде строк, поэтому преобразовываем исходные даннные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'the', u'happy', u'bastard', u\"'\", u's', u'quick', ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negreviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negreviews_str =[' '.join(review) for review in negreviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posreviews_str =[' '.join(review) for review in posreviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = negreviews_str + posreviews_str\n",
    "labels = [0] * len(negreviews_str) + [1] * len(posreviews_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем CountVectorizer с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x39659 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 666842 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = CV.fit_transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_frequent_words(X, vocabulary):\n",
    "    Frequencys = {}\n",
    "    invert_dict= {}\n",
    "    for key in vocabulary.keys():   \n",
    "        invert_dict.update({vocabulary.get(key):key}) \n",
    "    for i in xrange(0,X.shape[1]):\n",
    "        Frequencys.update( { invert_dict.get(i) : sum(X[:,i]) } )\n",
    "    Frequencys = sorted(Frequencys.items(), key=lambda x:x[1],reverse=True)     \n",
    "    \n",
    "    return Frequencys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 76529), (u'and', 35576), (u'of', 34123), (u'to', 31937), (u'is', 25195), (u'in', 21822), (u'it', 16107), (u'that', 15924), (u'as', 11378), (u'with', 10792), (u'for', 9961), (u'his', 9587), (u'this', 9578), (u'film', 9517), (u'he', 8864), (u'but', 8634), (u'on', 7385), (u'are', 6949), (u'by', 6261), (u'be', 6174)]\n"
     ]
    }
   ],
   "source": [
    "print get_frequent_words(X,CV.vocabulary_)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками), оценка качества по accuracy и ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836021650393\n"
     ]
    }
   ],
   "source": [
    "print cross_val_score(text_classifier(CountVectorizer(), LogisticRegression()), texts, labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910776493783\n"
     ]
    }
   ],
   "source": [
    "print cross_val_score(text_classifier(CountVectorizer(), LogisticRegression()), texts, labels,scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение логистической регрессии на всей доступной выборке и опредедение наиболее важных для модели признаков (слов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = text_classifier(CountVectorizer(), LogisticRegression()).fit(texts, labels)\n",
    "array_of_coef = b.named_steps['classifier'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Наиболее значимые, весомые слова \n",
    "def major_words(array_of_coef,vocabulary,n_words=20):\n",
    "\n",
    "#array_of_coef - массив коэффициентов линейной регрессии LogisticRegression().coef_\n",
    "#vocabulary - словарь CountVectorizer().vocabulary_\n",
    "#n_words - количество возвращаемых слов\n",
    "   \n",
    "    invert_vocabulary = {}\n",
    "    for key in vocabulary.keys():   \n",
    "        invert_vocabulary.update({vocabulary.get(key):key})\n",
    "   \n",
    "    # Если нужет топ 'ругательств' убрать abs() и поменять reverse=False\n",
    "    major_words= {}\n",
    "    for g in xrange(0,len(array_of_coef[0])):\n",
    "         major_words.update({g: abs(array_of_coef[0][g])}) \n",
    "        #major_words.update({g: array_of_coef[0][g]}) \n",
    "        \n",
    "    major_words = sorted(major_words.items(), key=lambda x:x[1],reverse=True)   \n",
    "    #major_words = sorted(major_words.items(), key=lambda x:x[1])   \n",
    "    \n",
    "    array_of_words=[]\n",
    "    for i in xrange(0,n_words):\n",
    "        array_of_words.append(invert_vocabulary.get(major_words[i][0]))\n",
    "        \n",
    "    \n",
    "    return array_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bad',\n",
       " u'unfortunately',\n",
       " u'worst',\n",
       " u'fun',\n",
       " u'waste',\n",
       " u'nothing',\n",
       " u'script',\n",
       " u'awful',\n",
       " u'boring',\n",
       " u'only',\n",
       " u'great',\n",
       " u'plot',\n",
       " u'poor',\n",
       " u'reason',\n",
       " u'back',\n",
       " u'looks',\n",
       " u'mess',\n",
       " u'supposed',\n",
       " u'lame',\n",
       " u'quite']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_words(array_of_coef,CV.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       1. Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оценено среднее качество ( .mean() ) и стандартное отклонение (.std()) по fold'ам для:\n",
    "        а) pipeline из CountVectorizer() и LogisticRegression(),\n",
    "        б) pipeline из TfidfVectorizer() и LogisticRegression(). \n",
    "\n",
    "        2. Изменяем параметр min_df (min document frequency) у CountVectorizer: min_df=10 и с min_df=50.\n",
    "        \n",
    "        3. Меняем классификатор, используемый после CountVectorizer. Сравниваем результаты для LogisticRegression, LinearSVC и SGDClassifier. \n",
    "        \n",
    "        4. Используем список стоп-слов с помощью nltk.corpus.stopwords.words('english') и собственный список стоп-слов sklearn. \n",
    "        \n",
    "        5. Добавляем в CountVectorizer биграммы.\n",
    "        \n",
    "        6. Строим модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR = cross_val_score(text_classifier(CountVectorizer(), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841\n",
      "0.0167779617356\n"
     ]
    }
   ],
   "source": [
    "print CVLR.mean()\n",
    "print CVLR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFLR =  cross_val_score(text_classifier(TfidfVectorizer(), LogisticRegression()), texts, labels,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821\n",
      "0.00406201920232\n"
     ]
    }
   ],
   "source": [
    "print TFLR.mean()\n",
    "print TFLR.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR50 = cross_val_score(text_classifier(CountVectorizer(min_df=50), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813\n",
      "0.0134536240471\n"
     ]
    }
   ],
   "source": [
    "print CVLR50.mean()\n",
    "print CVLR50.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR10 = cross_val_score(text_classifier(CountVectorizer(min_df=10), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839\n",
      "0.0118953772534\n"
     ]
    }
   ],
   "source": [
    "print CVLR10.mean()\n",
    "print CVLR10.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR = cross_val_score(text_classifier(CountVectorizer(), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841\n",
      "0.0167779617356\n"
     ]
    }
   ],
   "source": [
    "print CVLR.mean()\n",
    "print CVLR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLinR = cross_val_score(text_classifier(CountVectorizer(), LinearSVC()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325\n",
      "0.0162788205961\n"
     ]
    }
   ],
   "source": [
    "print CVLinR.mean()\n",
    "print CVLinR.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVSGDC = cross_val_score(text_classifier(CountVectorizer(), SGDClassifier()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7545\n",
      "0.111740771431\n"
     ]
    }
   ],
   "source": [
    "print CVSGDC.mean()\n",
    "print CVSGDC.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLRstop_1 = cross_val_score(text_classifier(CountVectorizer(stop_words=stopwords), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8415\n",
      "0.0104403065089\n"
     ]
    }
   ],
   "source": [
    "print CVLRstop_1.mean()\n",
    "print CVLRstop_1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLRstop_2 = cross_val_score(text_classifier(CountVectorizer(stop_words='english'), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8385\n",
      "0.00982344135219\n"
     ]
    }
   ],
   "source": [
    "print CVLRstop_2.mean()\n",
    "print CVLRstop_2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR_2 = cross_val_score(text_classifier(CountVectorizer(ngram_range=(1, 2)), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8525\n",
      "0.0165075740192\n"
     ]
    }
   ],
   "source": [
    "print CVLR_2.mean()\n",
    "print CVLR_2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVLR_35 = cross_val_score(text_classifier(CountVectorizer(ngram_range=(3, 5),analyzer='char_wb'), LogisticRegression()), texts, labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.0106066017178\n"
     ]
    }
   ],
   "source": [
    "print CVLR_35.mean()\n",
    "print CVLR_35.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
